%\begin{figure}[h!]
  %\begin{center}
    %\includegraphics* [width=0.8\linewidth]{figures/benchmarks/filter-fv1-fv2}
    %\caption{Filter Stage: F$(v1)$ vs F$(v2)$}
    %\label{fig:fv1-fv2-filter}
  %\end{center}
%\end{figure}

The merger as required by the \ac{NFQL} specification suggests matching each
group record from one branch with every other record of each branch. This
leads to a complexity of $O(n^m)$ where $n$ is the number of filtered group
records and $m$ is the number of branches. The possible number of tries when
matching group records however can be reduced by sorting the group records on
the field offsets used for a match. The merger, is now smart enough to skip
over iterator permutations \marginpar{skipping iterator permutations on sorted
group records} when a state of a current field offset value may not allow any
further match beyond the index in the current branch. For such an optimization
to work, the filtered group records must be sorted in the order of field
offsets specified in the merger clause. Specifying the filtered group records
in any other order may lead to undefined behavior. This means, that the terms
in the group clause must be arranged in such a way so to align with the order
of terms in the merger clause.

The \ac{NFQL} specification bases the merger matches on the notion of matched
tuples. This means that a filtered group record can be written to a file
multiple times if it is part of multiple matched tuples. This situation is
very common and it worsens when different branches have similar filtered
groups records. Since, the function of the merger is to find a match of groups
records across branches based on a predefined \marginpar{matched collections
over matched tuples} condition, all the group records across branches that
satisfy the condition can be clubbed into one collection instead of separate
tuples. All the group records within a collection can then be written to the
file. This eliminates the inherent redundancy and significantly improves the
merger performance. The implementation of this approach incurs a
reimplementation of the ungrouper. The ungrouper, as a result now accepts a
collection of matched filtered group records as input. It then iterates over
each collection to unfold it groups and write their flow record members to
files.

The performance comparison of this approach against the one suggested by the
specification is tricky. The merger implementation of the original
specification is slow. It is so slow that it keeps churning the CPU for days
without results. The newer approach takes less than an hour. The performance
evaluation of this newer approach is discussed in more details in
\marginpar{performance comparison and present issues} the next chapter. The
newer approach however is not currently pushed to \texttt{master} git
branch\footnote{The newer merger implementation is available in the
\texttt{fastmerger} git branch}. This is because the newer merger
implementation currently does not adapt itself to sort the filtered group
records on the field offset hit by the terms defined in the merger clause,
that do not exist in the grouper clause. In addition, more test cases need to
be defined to ensure that the newer merger works well with a variety of
\ac{NFQL} queries before pushing it to the mainstream branch.
